# Unbiasing through Textual Descriptions: Mitigating Representation Bias in Video Benchmarks
by [<ins>Nina Shvetsova</ins>](https://ninatu.github.io/), 
[<ins>Arsha Nagrani</ins>](https://a-nagrani.github.io/),
[<ins>Bernt Schiele</ins>](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele),
[<ins>Hilde Kuehne</ins>](https://hildekuehne.github.io/),
[<ins>Christian Rupprecht</ins>](https://chrirupp.github.io/).

ðŸ“„ [Project Webpage](https://utd-project.github.io) | ðŸ“š arXiv preprint: *coming soon*  
âœ¨ The paper has been accepted at **CVPR 2025**!

This repository will contain the **official implementation**.

ðŸš§ **Code and models will be released soon. Stay tuned!**

---

## ðŸ“‚ UTD Dataset

The **UTD (Unbiasing through Textual Descriptions)** dataset has been released and can be accessed via our [project webpage](https://utd-project.github.io). It includes:
- **UTD-descriptions**: structured frame-level annotations for 1.9M videos across 12 popular video benchmarks.
- **UTD-splits**: object-debiased test/val splits (and object-debiased-balanced splits for activity recognition datasets).

ðŸ‘‰ Head to the [project webpage](https://utd-project.github.io) for download links and detailed documentation.

---

## ðŸ“Œ Citation

If you use our dataset or method, please cite:

```bibtex
@inproceedings{shvetsova2025utd,
  title     = {Unbiasing through Textual Descriptions: Mitigating Representation Bias in Video Benchmarks},
  author    = {Shvetsova, Nina and Nagrani, Arsha and Schiele, Bernt and Kuehne, Hilde and Rupprecht, Christian},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2025}
}
